


[{"content":"I\u0026rsquo;m a big data engineer and blockchian enthusiast. I also have a Wiki generated by Obsidian \u0026amp; Quartz to use as a data engineer works experiences valut. In my spare time, I like to ride between the city and the mountains. Welcome to follow me on Strava. For my other social media accounts, you can visit my Bento.\nI believe that life is not measured by time, but by experience. So I\u0026rsquo;m always exploring.\n","date":"17 November 2024","externalUrl":null,"permalink":"/en/","section":"","summary":"","title":"","type":"page"},{"content":" ","date":"17 November 2024","externalUrl":null,"permalink":"/en/docs/","section":"Posts","summary":"","title":"Posts","type":"docs"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/tags/aliyun/","section":"Tags","summary":"","title":"Aliyun","type":"tags"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/tags/data-compute/","section":"Tags","summary":"","title":"Data-Compute","type":"tags"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/tags/tools/","section":"Tags","summary":"","title":"Tools","type":"tags"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/tags/tutorial/","section":"Tags","summary":"","title":"Tutorial","type":"tags"},{"content":" Bookmark Manager # hoarder-app/hoarder A self-hostable bookmark-everything app (links, notes and images) with AI-based automatic tagging and full text search TypeScript 5902 194 ","date":"16 November 2024","externalUrl":null,"permalink":"/en/week/20241103/","section":"Weekly Report","summary":"About my development tooks as data engineer","title":"W3 ","type":"week"},{"content":" Articel Transform、Tech Newsletter ","date":"16 November 2024","externalUrl":null,"permalink":"/en/week/","section":"Weekly Report","summary":"","title":"Weekly Report","type":"week"},{"content":"","date":"16 November 2024","externalUrl":null,"permalink":"/en/series/%E4%BA%A7%E5%93%81/","section":"Series","summary":"","title":"产品","type":"series"},{"content":" 个人资产管理APP # actualbudget/actual A local-first personal finance app TypeScript 15562 1206 ","date":"1 November 2024","externalUrl":null,"permalink":"/en/week/20241101/","section":"Weekly Report","summary":"About my development tooks as data engineer","title":"W1 op ","type":"week"},{"content":"I always try to find time to work and learn something new. Usually, most of these pet-projects don\u0026rsquo;t see the light of day. They are, however, great opportunities to try something in the real world and learn from it.\nDownloaded Resume PDF Job Infomation # Company Link Roles Date China Mobile Technology (Hangzhou) 移通科技（杭州）有限公司 Data Architect Data Producter 2022-2024 Whale Cloud Technology 浩鲸云计算科技股份有限公司 Data Development Data Delivery 2021-2022 ISoftStone Information Technology 软通动力信息技术（集团）股份有限公司 Data Development 2019-2020 Projects # Project Link Description Date 共富大脑 Active 针对政务系统数据数字改革，进行共富大脑数据底座的搭建及数据驾驶的开发. 2022-2023 WFP HungerMap Active 通过对90多个国家的粮食安全状况进行近实时监测, 通过数据模型和算法模型的预测分析, 为更好的决策提供依据. 2020-2021 Carso Sears Active 负责美西Carso数据中台的建设, 数据模型（维度建模）和数据指标的设计开发, 数据治理的治理和数据可视化的实现 2021-2022 react-portfolio Active About a peronal profile built with react, vite. 2023-2024 University # University Link Major Date REMIN UNIVERSITY OF CHINA 中国人民大学 Active Human Resource Management 2019-2022 Hebei Voeational University of Industry and Technology 河北工业职业技术学院 Active Electrical Automation 2015-2018 ","date":"12 June 2024","externalUrl":null,"permalink":"/en/resume/","section":"Resume","summary":"This is my personal resume.","title":"Resume","type":"resume"},{"content":"About my Digital Nomad life includ travel, movies, fitness, bike, frisbee, swimming, on foot ans so on.🥏 🚴 🏋️‍♀️ 🧘‍♀️ 🏊‍♂️ 🚴🏻 🎮 🎲 🎱 🎾 🏀 🍔\n","date":"2024.04.04","externalUrl":null,"permalink":"/travel/","section":" Experience","summary":"","title":" Experience","type":"travel"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/travel/midnight-restaurant-dali/","section":" Experience","summary":"每个人都有的深夜食堂，在大理的这部分","title":"【深夜食堂】大理","type":"travel"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/tags/coffee/","section":"Tags","summary":"","title":"Coffee","type":"tags"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/tags/dali/","section":"Tags","summary":"","title":"Dali","type":"tags"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/tags/digitalnomad/","section":"Tags","summary":"","title":"DigitalNomad","type":"tags"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/series/life/","section":"Series","summary":"","title":"Life","type":"series"},{"content":"","date":"2024.04.04","externalUrl":null,"permalink":"/tags/travel/","section":"Tags","summary":"","title":"Travel","type":"tags"},{"content":" 安吉 # 大理 # 天星村 # 深圳蛇口 -花房咖啡 # 花房 Coffee 20231212 杭州 # ","date":"2024.03.03","externalUrl":null,"permalink":"/travel/nature-desktop/","section":" Experience","summary":"","title":"游民工位","type":"travel"},{"content":" 蓄谋已久的虎跳峡两日游 # Day01: 从大理到香格里拉 # 张老师客栈 # 租车到徒步出发点 # 途中点：xx客栈 # 途中点：山顶咖啡 # Day02: 虎跳峡后半程 # 途中点01：Halfway # 途中点02: 小瀑布 # 途中点03: 虎跳峡拍照打卡点 # Day02：返程 # ","date":"2024.03.03","externalUrl":null,"permalink":"/travel/hutiaoxia/","section":" Experience","summary":"穿梭在香格里拉大峡谷，我们在虎跳峡徒步","title":"【徒步】虎跳峡","type":"travel"},{"content":"","date":"2024.03.03","externalUrl":null,"permalink":"/tags/hike/","section":"Tags","summary":"","title":"Hike","type":"tags"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/series/documments/","section":"Series","summary":"","title":"Documments","type":"series"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/pandas/","section":"Tags","summary":"","title":"Pandas","type":"tags"},{"content":" 案例目的 # 基于对 European Centre for Disease Prevention and Control 提供的COVID 19公开的数据集，使用Pandas做对应的数据分析\n数据集环境准备 # python 环境 # Warning! Python 3.+ is the latest. 创建一个新的python容器环境\nconda create --name covid conda activate covid 下载数据 # Data on COVID-19 vaccination in the EU/EEA \u0026ndash; Download in CSV\n将离线数据导入 # Warning! 注意编码格式，使用UTF-8会解析错误 import pandas as pd import numpy as np ## 加载数据 df = pd.read_csv(\u0026#34;covid-19-cases-march-28-2020.csv\u0026#34;) ### 查看数据的基本信息 print(df.info()) 多维查询和分析 # 查看数据基本信息 # df.count() 处理缺失值、运行程序，测试数据 # # 检查是否有缺失值 print(df.isnull().sum()) # 如果有缺失值，可以选择填充或删除 df = df.fillna(0) # 这里将缺失值填充为0 df.head(10) df.describe() 计算每个国家的总新增病例和总死亡人数 # country_summary = df.groupby(\u0026#39;countriesAndTerritories\u0026#39;).agg({ \u0026#39;cases\u0026#39;: \u0026#39;sum\u0026#39;, \u0026#39;deaths\u0026#39;: \u0026#39;sum\u0026#39; }) print(country_summary) 使用 numpy 进行更复杂的分析，计算每百万人新增病例的均值、标准差 # import matplotlib.pyplot as plt # 设置国家和日期范围 country = \u0026#39;Afghanistan\u0026#39; country_data = df[df[\u0026#39;countriesAndTerritories\u0026#39;] == country] dates = pd.to_datetime(country_data[\u0026#39;dateRep\u0026#39;], dayfirst=True) # 绘制每日新增病例 plt.figure(figsize=(10, 5)) plt.plot(dates, country_data[\u0026#39;cases\u0026#39;], label=\u0026#34;Daily Cases\u0026#34;) plt.plot(dates, country_data[\u0026#39;deaths\u0026#39;], label=\u0026#34;Daily Deaths\u0026#34;, color=\u0026#39;red\u0026#39;) plt.title(f\u0026#39;COVID-19 Daily Cases and Deaths in {country}\u0026#39;) plt.xlabel(\u0026#39;Date\u0026#39;) plt.ylabel(\u0026#39;Count\u0026#39;) plt.legend() plt.show() 在线代码 # Online Code ","date":"2023.12.12","externalUrl":null,"permalink":"/docs/use-pandas-exploring-covid-19-data/","section":"博客文章","summary":"通过对European Centre for Disease Prevention and Control提供的数据集，使用Pandas做简要数据分析","title":"Use Pandas Analysis By exploring COVID-19 Data","type":"docs"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/bigdata/","section":"Tags","summary":"","title":"Bigdata","type":"tags"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/cdo/","section":"Tags","summary":"","title":"CDO","type":"tags"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/job/","section":"Tags","summary":"","title":"Job","type":"tags"},{"content":" 1: English-level-up-tips # byoungd/English-level-up-tips An advanced guide to learn English which might benefit you a lot 🎉 . 离谱的英语学习指南/英语学习教程。 HTML 37074 4130 About：一个关于学习英语的高级指南，旨在帮助人们提升他们的英语水平。这个项目包含了许多章节，资源和指南，旨在为学习者提供全面的学习体验和帮助。项目的作者提供了一些关于学习英语的心得和技巧，以及一些个人成长经历的分享，希望能够激励更多人热爱学习英语并享受学习的乐趣。项目还包括了关于英语水平等级以及其他相关主题的内容，以帮助学习者更好地了解英语学习的路径和方法\n2: Everyone Can Use English # ZuodaoTech/everyone-can-use-english 人人都能用英语 TypeScript 25099 3772 About：知识库旨在帮助人们学习英语，其中包含了1000个小时的学习内容。这个知识库可能包含了英语学习的各种资源，例如单词列表、语法规则、练习题等，旨在帮助用户提高英语水平。通过这个知识库，用户可以系统地学习英语，提升听、说、读、写的能力，从而更好地运用英语进行交流和沟通。\n3: English Note # hzpt-inet-club/english-note 从0开始学习英语语法 null 2777 269 About：这个项目由 xiaoxunyao 提出，并且大量文本编辑的工作由他负责查阅资料和整理资料完成。在这个社会学会英语对于每位程序员的帮助都是有重大意义的，所以 INet 社区开始着手编写语法笔记，争取将复杂困难的语法知识点掰碎了告诉大家。\n4: Chinese Programmer Wrong Pronunciation # antfu/cpwp Chinese Programmer Wrong Pronunciation Vue 113 11 About：这个项目帮助中国程序员纠正常见的英语发音错误，特别是与技术术语和编程语言相关的词汇。仓库提供了一个常见错误发音的单词列表，并附上正确发音和常见错误。这个资源对于经常使用英语工作但可能没有机会学习特定技术术语正确发音的程序员和技术专业人员特别有用。Download Apps\n","date":"2023.12.12","externalUrl":null,"permalink":"/docs/learning-english-by-github/","section":"博客文章","summary":"Everyday doing things.","title":"Learning English By Github","type":"docs"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/macbook/","section":"Tags","summary":"","title":"Macbook","type":"tags"},{"content":" macbook-env # 常用开发工具 # 代码编辑器 # VS Code - 通用代码、文本编辑器 PyCharm - Python 开发集成环境，管理构建多个python项目的开发，测试，运维 IntelliJ IDEA - 用于构建 Java 开发集成环境 DataGrip - 用于数据库和SQL的跨平台IDE GoLand - JetBrains出品的Go开发IDE，智能，灵活 Webstorm - 是 JetBrains 公司旗下一款 JavaScript 开发工具 JetBrains Toolbox App - 管理已安装的JetBrains工具，下载新工具并打开最近的项目 文本编辑器 # Sublime Text - 一个比较简洁大方带插件管理系统的流行编辑器，Sublime常用插件。 ![Awesome List][awesome-list Icon] He3 - 免费智能的开发者万能工具箱. 命令行工具 # iTerm2 - 免费的终端工具，直接替代自带的 Terminal，有非常多惊人的特性 Termius-beta - 免费的终端工具，可以与 windows 平台的 xshell 媲美。 autojump - 告别又臭又长的路径名，一键直达任何目录。 mycli - 为 MySQL 命令行客户端，提供语法高亮和提示功能的工具！ tldr - Collaborative cheatsheets for console commands ndm - 查看本地NPM安装的包客户端软件。摆脱命令方便安装、查看、卸载软件。 color-retro-term - 一款复古风格的终端，非常酷炫。 ttygif - 将终端录制转换为 GIF 动画。 数据库 # Another Redis Desktop Manager - 一款稳定全新的Redis管理工具。 Navicat Data Modeler - 一个数据库设计工具，它帮助创建高质素的概念、逻辑和物理数据模型。 MongoDB - 一个基于分布式文件存储的数据库。 网络 # Proxyman - 适用于 macOS 的现代直观 HTTP 调试代理. 设计 # StarUML - 强大的软件建模软件 Figma - Work Chrome Extensions # Immersive Translate - good translation iTab New Tab - Refined tab page Refined GitHub - No-brainer must-have Tampermonkey - User scripts for any website File Icons for GitHub and GitLab - It looks very nice! Grammarly - Spell check uBlock Origin - Ad blocker I don\u0026rsquo;t care about cookies - Disable cookie popups, probably more relevant in EU Ajax Interceptor - To modify response text of ajax requests Dark Reader - Dark mode for every website JSONVue - Validate and view JSON documents Super Simple Highlighter - Make permanent, private highlights on any web page Wappalyzer - Technology profiler - Identify web technologies MacOS Productivity # Arc - The internet computer default browser Raycast - Spotlight replacement SwitchHosts Kap - GIF Recorder MonitorControl - Control the monitor in macOS Picsee - File-based photo management Command X - The missing Cut feature for finder Rectangle - Window Manager PP Duck - Image compression artifact Paste - Clipboard manager WeChat Reading - WeChat reader Dynamic Wallpaper Engine - 4K Dynamic Wallpaper Flux - Light Perculia - Bluetooth assistant Tencent Lemon - Clean Thor Launcher - Open the right application ASAP RunCat - Cat living in the menubar iTerm2 - Terminal Media # photo # magiceraser - 几秒钟内删除不需要的对象、人物和文本 remove.bg - 在线抠图软件_图片去除背景 References # antfu/use sorrycc/awesome-tools ","date":"2023.12.12","externalUrl":null,"permalink":"/docs/my-macbook-use/","section":"博客文章","summary":"About Personal Macbook Application, Tools, Product, Settings..","title":"My Macbook Use","type":"docs"},{"content":"","date":"2023.12.12","externalUrl":null,"permalink":"/tags/resources/","section":"Tags","summary":"","title":"Resources","type":"tags"},{"content":" Chief Data Officer: 首席数据官 简称：CDO\n首席数据官的定义 # 负责企业的数据战略、治理、分析与创新，是数字时代的必然产物\nCDO 产生的背景 # 《领导者数据宣言》，强调数据的重要性，呼吁领导者关注数据资产，通过CDO发起数据革命。 数据是数字经济的基础，是数字时代的核心资产 数字化转型需要管理好、治理好数据 企业数据需要从IT中分离出来，聚焦数据资产的管理（DAMA-DMBOK2） CDO的主要职责和组织架构 # 数据战略：制定企业级数据战略规划；建立数据驱动的业务决策机制；推动数据资产变现和商业价值实现 数据治理：管好数据，实现数据价值；建立统一的数据标准和管理制度；确保数据安全与合规；制定数据生命周期管理策略 技术赋能：规划数据基础设施建设；推动数据中台、智能平台建设；建设数据分析和AI能力 建好团队：建立数据治理组织架构；培养企业数据团队；提升全员数据意识；推动数据文化建设 做好转型：相应、促进和引领数据转型 首席数据官的挑战 # 数据孤岛问题：企业的数据往往分散在不同的部门和系统中，形成所谓的“数据孤岛”。CDO 需要打破这些孤岛，实现数据的统一管理和共享。 数据质量问题：确保数据的准确性和一致性是一项长期的挑战。低质量的数据会导致错误的分析结果和不良的决策，因此 CDO 需要推动企业数据的清洗、验证和治理工作。 推动文化变革：转变企业的传统业务模式，推动数据驱动文化可能面临阻力。CDO 需要教育和激励员工，使他们接受并应用数据工具。 技术快速变化：数据技术和工具在不断变化，CDO 需要保持对最新技术的敏感度，并不断引入适合企业的数据工具和平台。 CTO重要时刻 # 1988, DAMA首次提出数据官的概念 明确强调了数据资产在数字时代的核心作用和意义 2002, 凯瑟琳·克莱·多斯 被任命为Capital One首席数据官 2005, Usama Fayyad 被任命为雅虎首席数据官兼高级副总裁 2005, EDMC成立 企业数据管理委员会(Enterprise Data Mangerment Council),早先由美国华尔街的十几家著名机构（花旗、高盛）组成，后成立DCAM，CDMC。专注数据标准和数据资产，培养了大量数据人员 2007, CDOIQ成立 国际首席数据官和信息质量研究会（International Chief Data Officer and Infomation Quality Symposium）,该机构目的是分享和交流关于数据和首席数据官的前沿思想、理论和最佳实践 2013, isDAO成立 国际首席数据官协会成立（International Society of Chief Data Officers）,由CDO成员组成, 目的是确保世界各地CDO能够更好的发挥他们的作用。与ComSpark合作著有CDO Magazine 2015, 首个数据官 欧洲的CDO首先在法国被任命 2017, 数据领导者组织成立 该组织在EDW大会上发布《领导者数据宣言》，明确强调了数据资产在数字时代的核心作用和意义 2020, 美国联邦政府成立首席数据官委员会 其他CDO 乌萨马·法耶兹是雅虎的第一位CDO Philip Bourne是美国国立卫生研究院数据科学副主任 Ashok Srivastava是Intuit的首席数据官，在该公司领导人工智能和机器学习 Resource # CDO Magazine What is digital transformation? Everything you need to know ","date":"2023.12.12","externalUrl":null,"permalink":"/docs/003-cdo/","section":"博客文章","summary":"首席数据官（CDO）是数字时代的必然产物，在企业数据管理、数据战略、数据治理、数字资产、数字经济中的作用越来越重要","title":"首席数据官(CDO)的自我修养","type":"docs"},{"content":"","date":"2023.05.05","externalUrl":null,"permalink":"/tags/bi/","section":"Tags","summary":"","title":"BI","type":"tags"},{"content":"","date":"2023.05.05","externalUrl":null,"permalink":"/tags/charts/","section":"Tags","summary":"","title":"Charts","type":"tags"},{"content":" 产品介绍 # Quick BI 提供智能化数据分析及可视化能力，满足用户数据准备、数据分析、数据可视化等需求\n技术解决方案 # 统一登录门户方案 查询加速方案 资源集中化管控方案 开放审批流方案 租户安全隔离方案 可视化解决方案 工作流 # graph LR; A[Connect Data Origin]--\u003eB[Create Data Model] B--\u003eC[Data Visualization] C--\u003eD[Publish \u0026 Share] 业务场景 # 功能列表 # 开放集成 事件中心 事件中心 开放统计 登录认证 自定义组件 报表嵌入统计 报表嵌入统计 开放API 自定义菜单 API调用统计 API调用统计 嵌入分析 自定义模板 数据服务 自定义连接器 自定义插件 # ","date":"2023.05.05","externalUrl":null,"permalink":"/docs/aliyun-quickbi/","section":"博客文章","summary":"Aliyun Visual Charts Tools","title":"QucikBI","type":"docs"},{"content":"","date":"2023.04.04","externalUrl":null,"permalink":"/tags/database/","section":"Tags","summary":"","title":"Database","type":"tags"},{"content":"","date":"2023.04.04","externalUrl":null,"permalink":"/tags/odps/","section":"Tags","summary":"","title":"ODPS","type":"tags"},{"content":" 1. 开发流程 # 1.1 数据调研 # 1.1.1 业务调研 # 熟悉业务流程：明确每个现实业务的具体流程，拆分为抽象的业务过程（不可拆分的行为事件）\n熟悉业务数据：将数据与业务过程对应起来，明确每个业务过程对_哪些_表的数据产生_哪些_影响（具体到对表、数据条目的操作逻辑）\n1.1.2 需求分析 # 明确需求所需的业务过程及维度\n业务数据汇总标准，衡量标准\n明细数据层和汇总数据层设计，公共维度层设计，公共的指标设计\n数据是否需要冗余或沉淀到汇总数据层中\n1.2 数据划分 # 数据划分是指面向业务、数据域、业务过程、部门分析，将业务过程或者维度进行抽象的集合\n目的：便于数据的管理和应用\n基本原则：\n为保障整个体系的生命力，数据划分是需要抽象提炼，并且长期维护和更新的，但不轻易变动\n既能涵盖当前所有的业务需求，又能在新业务进入时无影响地被包含进已有的数据划分中和扩展新的数据划分\n划分：\n按业务划分：这里业务可以指功能模块、业务线，甚至是项目。命名时按主要的业务划分，以指导物理模型的划分原则和命名原则。\n按数据域划分：将一个或多个业务过程、维度进行抽象的集合。\n按业务过程划分：当一个数据域由多个业务过程组成时，可以按业务流程划分。业务过程是从数据分析角度看客观存在的或者抽象的业务行为动作。\n按照部门划分：根据数据归属部门来划分数据。\n1.3 构建业务总线矩阵 # 包含所有事实（业务过程）及维度，以及两者之间的关系\n矩阵的行是业务过程，列是维度\n一个业务过程对应一张事务型事实表，一个维度则对应一张维度表\n1.4 明确统计指标 # 原子指标 ： 业务过程 + 度量值 + 聚合逻辑\n派生指标 ： 原子指标 + 统计周期 + 业务限定（修饰词） + 统计粒度（groupBy）\n衍生指标 ： 在一个或多个派生指标的基础上计算而来\n当需求足够多时，建议将公共的派生指标保存在数仓的DWS层，减少重复计算，提高数据的复用性。\n1.5 维度模型设计 # 构建业务总线矩阵的过程就是设计维度模型的过程。但是需要注意，总线矩阵中通常只包含事务型事实表，周期性快照事务表和累积型快照事实表这两种类型的事实表需单独设计\n事实表存储在DWD层\n维度表存储在DIM层\n1.6 汇总模型设计 # 汇总模型的设计参考整理出的指标体系\n汇总表与派生指标的对应关系是：一张汇总表通常包含业务过程相同、统计周期相同、统计粒度相同的多个派生指标\n2.数据模型架构规范 # 2.1 基本原则 # 高性能：快速查询\n低成本：减少重复计算\n高效率：提高用户使用数据的效率\n高质量：减少计算错误可能性\n2.2 数据层次的划分 # 基本原则：\n减少重复开发\n数据血缘可追踪；\n清晰数据结构；\n避免链路过长；\n不能为了分层而分层\n划分：\nODS：Operational Data Store，操作数据层(原始数据层)，在结构上其与源系统的增量或者全量数据基本保持一致。相当于一个数据准备区，同时又承担着基础数据的记录以及历史变化。其主要作用是把基础数据引入到数仓中。是最接近数据源中数据的一层，为了考虑后续可能需要追溯数据问题，因此对于这一层就不建议做数据清洗工作。\nCDM：Common Data Model，公共维度模型层，又细分为DWD、DWS和DIM层。它的主要作用是完成数据加工与整合、建立一致性的维度、构建可复用的面向分析和统计的明细事实表以及汇总公共粒度的指标。同时在该层的DWD和DIM完成数据清洗、规范以及数据元的标准化。为了提高明细数据层的易用性，该层会采用一些维度退化手法，将部分维度退化至事实表中，减少事实表和维表的关联。\nDIM： Dimension，公共维度层，主要分为高基数维度数据、低基数维度数据和杂项维度数据。 DWD：Data Warehouse Detail，明细数据层。\nDWS：Data Warehouse Summary，汇总数据层。\nDWT：Data Warehouse Topic，主题数据层。\nADS：Application Data Service，应用数据层。\n具体仓库的分层情况需要结合业务场景、数据场景、系统场景进行综合考虑。\n2.3 数据分类架构 # 该数据分类架构在ODS层分为三部分：数据准备区、离线数据和准实时数据区。在进入到CDM层后，由以下几部分组成：\n公共维度层：基于维度建模理念思想，建立整个项目的一致性维度。\n明细粒度事实层：以业务过程为建模驱动，基于每个具体业务过程的特点，构建最细粒度的明细层事实表。可以结合数据使用特点，将明细事实表的某些重要维度属性字段做适当的冗余，即宽表化处理。\n公共汇总粒度事实层：以分析的主题对象为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标事实表或者面向实体的主题宽表，以宽表化手段来物理化模型。\n2.4 数据处理流程架构 # 2.5 主题域划分及命名约定 # 需要根据业务划分数据并约定命名，建议针对业务名称结合数据层次约定相关命名的英文缩写，这样可以给后续数据开发过程中，对项目/库、表、字段等命名作为重要参照。\n划分：\n按业务划分：这里业务可以指功能模块、业务线，甚至是项目。命名时按主要的业务划分，以指导物理模型的划分原则和命名原则。例如，按业务定义英文缩写，“志愿者服务”英文缩写可以定义为“vol”。\n按数据域划分：将一个或多个业务过程、维度进行抽象的集合。命名时按照CDM层的数据进行数据域划分，以便有效地对数据进行管理，以及指导数据表的命名。例如，“市场主体”数据的英文“market entity”缩写可定义为“mkt_ent”。\n按业务过程划分：当一个数据域由多个业务过程组成时，命名时可以按业务流程划分。业务过程是从数据分析角度看客观存在的或者抽象的业务行为动作。例如，市场主体域中的“主体变更”这个业务过程的英文缩写可约定命名为“ent_chg”。\n按照部门划分：根据数据归属部门来划分数据。例如，学生数据归属教育部门，英文缩写可以约定为“edu_stu”。\n2.6 数据模型 # 模型是对现实事物的反映和抽象。数据模型定义了数据之间关系和结构，可以有规律地快速获取想要的数据。例如，在一个超市里，商品的布局都有特定的规范，商品摆放的位置是按照消费者的购买习惯以及人流走向进行摆放的。\n（1）数据模型的作用：\n数据模型是在业务需求分析之后，数据仓库工作开始时的第一步。良好的数据模型可以更好地存储数据，更有效率地获取数据，保证数据间的一致性。\n（2）基本设计原则：\n高内聚和低耦合 一个逻辑和物理模型由哪些记录和字段组成，应该遵循最基本的软件设计方法论中的高内聚和低耦合原则，模型内部高内聚、 不同模型间低耦合。\n主要从数据业务特性和访问特性两个角度来考虑：\n将业务相近或者相关的数据、粒度相同数据设计为一个逻辑或者物理模型；\n将高概率同时访问的数据放一起，将低概率同时访问的数据分开存储。\n核心模型与扩展模型分离\n建立核心模型与扩展模型体系，核心模型包括的字段支持常用核心的业务，扩展模型包括的字段支持个性化或是少量应用的需要。在必须让核心模型与扩展模型做关联时，不能让扩展字段过度侵入核心模型，以免破坏了核心模型的架构简洁性与可维护性。\n公共处理逻辑下沉及单一 底层公用的处理逻辑应该在数据调度依赖的底层进行封装与实现，不要让公用的处理逻辑暴露给应用层实现，不要让公共逻辑在多处同时存在。\n成本与性能平衡 适当的数据冗余可换取查询和刷新性能，不宜过度冗余与数据复制。\n**数据可回滚，**处理逻辑不变，在不同时间多次运行数据的结果需确定不变。\n**一致性，**相同的字段在不同表中的字段名必须相同。\n**命名清晰可理解，**表命名规范需清晰、一致，表命名需易于下游的理解和使用。\n说明\n一个模型无法满足所有的需求。\n需合理选择数据模型的建模方式。\n通常，设计顺序依次为：概念模型-\u0026gt;逻辑模型-\u0026gt;物理模型。\n3. 公共规范 # 3.1 层次调用约定 # （1）应用层应优先调用公共层数据（必须存在中间层CDM数据），不允许应用层跨过中间层CDM从ODS层重复加工数据。\n（2）中间层CDM需要积极了解应用层数据的建设需求，将公用的数据沉淀到公共层，为其他层提供数据服务。\n（3）应用层需要积极配合中间层CDM持续改造公共层。必须避免不合理的数据复制以及子集合冗余。\nODS层数据不能被应用层任务引用，如果中间层没有沉淀的ODS层数据，则通过CDM层的视图访问。CDM层视图必须使用调度程序进行封装，保持视图的可维护性与可管理性。\nCDM层任务的深度不宜过大（建议不超过10层）。\n原则上一个计算刷新任务只允许一个输出表。\n如果多个任务刷新输出一个表（不同任务插入不同的分区）,Doplhinscheduler上必须通过创建一个Dependent任务节点，通过Dependent依赖上游所有刷新任务(DataWorks上需要建立一个依赖多个刷新任务的虚拟任务，通常下游应该依赖此虚拟任务)。\nCDM汇总层应优先调用CDM明细层。在调用可累加类指标计算时，CDM汇总层尽量优先调用已经产出的粗粒度汇总层，以避免大量汇总直接从海量的明细数据层计算。\nCDM明细层累计快照事实表优先调用CDM事务型事实表，以保持数据的一致性产出。\n避免应用层过度引用和依赖CDM层明细数据，需要针对性地建设好CDM公共汇总层。\n3.2 业务域粒度 # 按实际需求分配不同的业务域。例如：\nODS层项目，按业务域的粒度建立。\nCDM层项目，按业务域的粒度建立。\nADS层项目，按应用的粒度建立。\n3.3 分层命名规范 # ODS层名称以ods为前缀，例如ods\\_。\n中间层CDM名称以cdm为前缀，例如dim\\_、dwd\\_、dws\\_、cdm\\_。\n1）拉链表名称以zip为后缀，例如\\_zip。\n应用层ADS名称以ads为前缀，例如ads_。 1）数据报表、数据分析等应用名称以bi为后缀，例如\\_bi；\n2）数据产品等应用名称以app为后缀，例如\\_app。\n3.4 数据类型规范 # ODS层的数据类型应基于源系统数据类型转换。例如，源数据为MySQL时的转换规则如下。\nMySQL数据类型 Hive数据类型 MaxCompute数据类型 TINYINT TINYINT TINYINT SMALLINT/MEDIUMINT SMALLINT SMALLINT INTEGER INT INT BIGINT BIGINT BIGINT FLOAT FLOAT FLOAT DOUBLE DOUBLE DOUBLE DECIMAL DECIMAL DECIMAL CHAR/VARCHAR STRING STRING LONGTEXT/TEXT STRING STRING DATE/TIMESTAMP/TIME/YEAR STRING STRING DATETIME STRING DATETIME CDM数据公共层如果是引用ODS层数据，则默认使用ODS层字段的数据类型。其衍生加工数据字段按以下标准执行：\n金额类及其它小数点数据使用_DOUBLE或DECIMAL_类型。\n字符类数据使用_STRING_类型。\nID类和整形数值使用_BIGINT或INT_类型。\n时间类型数据使用_STRING或者DATETIME类型（如果有特殊的格式要求，可以选择性使用DATETIME_类型）。\n状态使用_STRING_类型。\n3.5 字段定义规范 # 数据统计日期的分区字段按以下标准：\n按天分区：dt(yyyymmdd或 yyyy-mm-dd)。\n按小时分区：hh(00~23)。\n按分钟：mi(00~59)。\nis_{业务}：表示布尔型数据字段。以Y和N表示，不允许出现空值域。\n原则上不需要冗余分区字段。\n所有单词小写\n单词之间下划线分割（反例：appName 或 AppName）\n可读性优于长度 (词根，避免出现同一个指标，命名一致性)\n禁止使用 sql 关键字，如字段名与关键字冲突时 +col\n3.6 数据冗余 # 一个表做宽表冗余维度属性时，应该遵循以下建议准则：\n冗余字段要使用高频，下游3个或以上使用。\n冗余字段的引入不应造成其本身的刷新完成时间产生过多后延。\n冗余字段和已有字段的重复率不应过大，原则上不应超过60%，如需要可以选择join或原表拓展。\n3.7 数据拆分 # 数据的_水平和垂直拆分是按照访问热度分布_和数据表非空数据值、零数据值在行列二维空间上分布情况进行划分的。\n在物理上划分核心模型和扩展模型，将其字段进行垂直划分。\n将访问相关度较高的列在一个表存储，将访问相关度较低的字段分开存储。\n将经常用到的Where条件按记录行进行水平切分或者冗余。水平切分可以考虑二级分区手段，以避免多余的数据复制与冗余。\n3.8 空值处理原则 # 汇总类指标的空值：空值处理，填充为0。\n维度属性值为空：空值处理，填充为NULL。\n3.9 指标口径规范 # 基本原则：\n至少保证本数据划分内，指标口径一致，无歧义。\n存在两个指标名称相同，但口径不一致，优先判断是否可以合并\n3.10 数据表处理规范 # 3.10.1 增量表 # 新增数据，增量数据是上次导出之后的新数据\n记录每次增加的量，而不是总量\n增量表，只报变化量，无变化不用报\n每天一个分区。\n**事件型流水表：**指数据无重复或者无主键数据，如日志\n**事件型镜像表：**指业务过程性数据，有主键，但是对于同样主键的属性会发生缓慢变化，如交易、订单状态与时间会根据业务发生变更\n3.10.2 全量表 # 每天的所有的最新状态的数据\n全量表，有无变化，都要归集\n每次归集的数据都是所有的数据（变化的 + 没有变化的）\n只有一个分区\n3.10.3 快照表 # 按日分区，记录截止数据日期的全量数据\n快照表，有无变化，都要报\n每次上报的数据都是所有的数据（变化的 + 没有变化的）\n一天一个分区\n3.10.4 拉链表 # 记录截止数据日期的全量数据\n记录一个事物从开始，一直到当前状态的所有变化的信息\n拉链表每次上报的都是历史记录的最终状态，是记录在当前时刻的历史总量\n当前记录存的是当前时间之前的所有历史记录的最后变化量（总量）\n只有一个分区\n3.11 词根设计规范 # ? 4. ODS层设计规范 # 4.1 设计原则 # 一个系统源表只允许同步一次\n全量初始化同步和增量同步处理逻辑要清晰\n以统计日期和时间进行分区存储\n目标表字段在源表不存在时要自动填充处理\n4.2 命名规范 # 表命名规则：{project_name/database}.ods_{源系统名}_业务域_主题域_XXX_更新周期\n增量数据：{project_name/database}.ods_{源系统名}_XXX_delta。\n全量数据：{project_name/database}.ods_{源系统名}_XXX。\nODS ETL过程的临时表：{project_name/database}.tmp_{临时表所在过程的输出表}_{从0开始的序号}。\n按小时同步的增量表：{project_name/database}.ods_{源系统名}_XXX_delta_{hh}。\n按小时同步的全量表：{project_name/database}.ods_{源系统名}_XXX_{hh}。\n当不同源系统同步到同一个Project/Database下的表命名冲突时，需要给同步较晚的表名加上源系统的dbname以解决冲突。\n字段命名规范\n字段默认使用源系统的字段名。\n字段名与MaxCompute/Hive关键字冲突时，在源字段名后加上col，即源字段名col。\n说明 ：\n任务的输出名称，即输出表的名称。\nDataworks中ODS表名命名可基于原表名加前缀和后缀的方式{project_name/database}.ods_{源系统名}_{原表名}_更新周期；\n4.3 数据存储及生命周期管理规范 # 数据表类型 存储方式 最长存储保留策略 ODS流水型全量表 按天分区 不可再生情况下，永久保存；日志可按留存要求； ODS镜像型全量表 按天分区 推荐按天存储；对历史变化进行保留；最新数据存储在最大分区；历史数据按需保留； ODS增量表 按天分区 推荐按天存储；有对应全量表，最多保留最近14天分区数据。无对应全量表，需要永久保留数据。 ODS ETL过程临时表 按天分区 推荐按需保留；最多保留最近7天分区；建议用完即删，下次使用再生成； 4.4 数据质量规范 # 每个ODS全量表必须配置唯一性字段标识；\n每个ODS全表必须有注释；\n每个ODS全量表必须监控分区空数据；\n建议对重要表的重要枚举类型字段进行枚举值变化及枚举值分布监控；\n建议ODS表数据量级和记录数做环比监控。\n必须给扩展src_sys字段和runtime字段，用于记录数据来源系统和入仓时间\n5 CDM公共维度层设计规范 # 维度表主要是包含一个主键，各种维度字段（维度属性）\n5.1 设计原则 # （1）一致性维度规范：\n公共层的维度表中相同维度属性在不同物理表中的字段名称、数据类型、数据内容必须保持一致。除了以下情况：\n在不同的实际物理表中，如果由于维度角色的差异，需要使用其他的名称，其他名称也必须是规范的维度属性的别名。例如，定义一个标准的身份证id_card时，如果在一个表中，分别要表示父亲身份证号，母亲身份证号，那么设计规范阶段就预先对身份证号分别定义父亲身份证号和母亲身份证号。\n如果由于历史原因，在暂时不一致的情况下，必须在规范的维度定义一个标准维度属性，不同的物理名也必须是来自标准维度属性的别名。\n若多个事实表与同一维度相关，应保证维度唯一性（只创建一张维度表）\n（2）维度属性\n尽量不编码，采用文字说明。 （3）维度的组合与拆分\n1）组合原则\n将维度所描述业务相关性强的字段在一个物理维表实现。相关性强是指经常需要一起查询或进行报表展现、两个维度属性间是否存在天然的关系等。例如，企业基本属性和法人代表。\n无相关性的维度可以适当考虑杂项维度（例如公民身份），可以构建一个公民身份杂项维度收集身份的特殊标记属性、分类等信息。也可以将杂项维度退化在事实表中处理，不过容易造成事实表相对庞大，加工处理较为复杂。\n行为维度是经过汇总计算的指标，在上层的应用使用时将其当维度处理。例如：救助次数1-5次，6-10次。如果有需要，度量指标可以作为行为维度冗余到维度表中。\n2）拆分与冗余\n对于维度属性过多，涉及源较多的维度表（例如自然人表），可以做适当拆分：\n拆分为核心表和扩展表。核心表相对字段较少，刷新产出时间较早，优先使用。扩展表字段较多，且可以冗余核心表部分字段，刷新产出时间较晚，适合数据分析人员使用。\n根据维度属性的业务不相关性，将相关度不大的维度属性拆分为多个物理表存储。\n数据记录数较大的维度表（例如停车用户表），可以适当冗余一些子集合，以减少下游扫描数据量：\n可以根据近半年是否登录过停车小程序，产出一个活跃的停车用户相关维表，以减少应用的数据扫描量。\n可根据所属业务扫描数据范围大小的不同，进行适当子集合冗余。\n（4）维度退化\n某维度表属性很少，此表可省略不创建，将该表的属性直接增加到相关的事实表中确定主维表和相关维表\n（5）维度变化\n1）全量快照\n优点：简单，有效。\n缺点：浪费空间\n2）拉链表\n记录信息的生命周期\n适用于变化频率不是很大的场景\n（6）多值属性\n多值属性放入同一字段\n多值属性放入多个字段，只适用于属性值固定的情况\n5.2 表命名规范 # 命名规则：{project_name/database}.dim[_{业务/pub}]_{维度定义}[_{自定义命名标签}]，其中的pub与具体业务无关，各个业务部都可以共用，例如时间维度、地区维度。\n5.3 数据存储及生命周期管理规范 # CDM公共维度层的表的类型为维度表，存储方式为按天分区。\n模型设计需要根据自身业务需求设置表的生命周期管理。可依据3个月内的最大需要访问的跨度设置保留策略，具体计算方式如下：\n当3个月内的最大访问跨度小于或等于4天时，建议将保留天数设为7天。\n当3个月内的最大访问跨度小于或等于12天时，建议将保留天数设为15天。\n当3个月内的最大访问跨度小于或等于30天时， 建议将保留天数设为33天。\n当3个月内的最大访问跨度小于或等于90天时，建议将保留天数设为93天。\n当3个月内的最大访问跨度小于或等于180天时， 建议将保留天数设为183天。\n当3个月内的最大访问跨度小于或等于365天时，建议将保留天数设为368天。\n6. CDM明细层设计规范 # 事实表主要包含与业务过程有关的维度引用（维度表外键）以及业务过程的度量（数字类型字段）\n事实表划分：\n事务事实表\n周期快照事实表\n累积快照事实表\n6.1 命名规范 # 命名规则：{project_name/database}.dwd[_{业务缩写/pub}]_{数据域缩写}_{业务过程缩写}_[{自定义表命名标签缩写}]_{刷新周期标识}{单分区增量全量标识}。\n命名说明：\npub表示数据包括多个业务的数据。\n刷新周期标识：mi表示分钟，h表示小时，d表示天，w表示周，m表示月，y表示年\n单分区增量全量标识：i表示增量，f表示全量。\n6.2 事务型事实表设计准则 # 事务型事实表主要用于分析行为与追踪事件。事务事实表获取业务过程中的事件或者行为细节，保存各业务过程的原子操作事件，最细力度的操作事件，然后通过事实与维度之间关联，可以非常方便地统计各种事件相关的度量，例如帮扶次数，救助时数等等。\n1）基于数据应用需求的分析设计事务型事实表，如果下游存在较大的针对某个业务过程事件的分析指标需求，可以考虑基于某一个事件过程构建事务型事实表。\n2）事务型事实表一般选用事件发生日期或时间作为分区字段，这种分区方式可以方便下游的作业数据扫描执行分区裁剪。\n3）明细层事实表的冗余子集的原则能有利于降低上层数据访问的IO开销。\n4）明细层事实表维度退化到事实表原则能有利于减少上层数据访问的JOIN成本。\n设计步骤：\n1）选择业务过程：一个业务过程对应一个事务型事实表\n2）声明粒度：为每个业务声明粒度（定义每行数据的具体含义，应尽可能最细）\n3）确认维度：确认与本表相关的维度（环境信息，尽量丰富）\n4）确认事实：确定业务的度量值\n6.3 周期快照型事实表 # 周期快照型事实表主要用于以规律、可预见的时间间隔记录事实，分析状态型或者存量型事实。快照是指以预定的时间间隔来采样状态度量。\n设计步骤：\n1）确定粒度：周期（通常选每日）、维度\n2）确认事实：业务过程、指标\n事实（度量值）类型：\n1）可加事实：可按照所有相关维度进行累加\n2）半可加事实：只能按照一部分相关维度进行累加\n3）不可加事实：没有可加性\n6.4 累计快照事实表 # 累计快照事实表是基于多个业务过程联合分析从而构建的事实表，一般具有多个日期字段，主要用于分析事件之间的时间间隔等需求。例如，数据申请工单的流转环节等，用初审、复审、终审之间的间隔来分析审核速度，或在审批中的撤回工单分析撤回率等。\n设计流程\n选择业务过程：一个业务流程中的多个关键业务过程（里程碑），多个关键业务过程对应一个累计型快照事实表\n声明粒度：定义每行数据的具体含义，应尽可能最细\n确认维度：选择与每个业务过程相关的维度，至少需要一个日期维度\n确认事实：各业务过程的度量值\n6.5 数据存储及生命周期管理规范 # CDM明细层的表的类型为事实表，存储方式为按天分区\n事务型事实表一般永久保存。周期快照型事实表根据业务需求设置生命周期管理。可依据3个月内的最大需要访问的跨度设置保留策略，具体计算方式如下：\n当3个月内的最大访问跨度小于或等于4天时，建议将保留天数设为7天。\n当3个月内的最大访问跨度小于或等于12天时，建议将保留天数设为15天。\n当3个月内的最大访问跨度小于或等于30天时， 建议将保留天数设为33天。\n当3个月内的最大访问跨度小于或等于90天时，建议将保留天数设为93天。\n当3个月内的最大访问跨度小于或等于180天时， 建议将保留天数设为183天。\n当3个月内的最大访问跨度小于或等于365天时，建议将保留天数设为368天。\n7. CDM汇总层设计规范 # 汇总层主要是通过汇总明细粒度或者维度数据来获得改进查询性能的效果。通过访问汇总层，可以减少数据在响应查询时必须执行的工作量，能够快速响应查询，同时有利于减少不同用访问明细数据带来的结果不一致问题。\n7.1 设计原则 # 一致性：汇总层必须提供与查询明细粒度和公共维度数据一致的查询结果。\n避免单一表设计：不要在同一个表中存储不同层次的汇总数据。\n汇总层粒度可不同。汇总并不需要保持与原始明细粒度数据一样的粒度，汇总只关心所需要查询的维度和度量。\n数据公用性\n不建议跨域\n7.2 命名规范 # 命名规则：{project_name/database}.dws/dwt[_{业务缩写/pub}]_{数据域缩写}_{数据粒度缩写}_[{自定义表命名标签缩写}]_{统计时间周期范围缩写}[_{刷新周期标识}{单分区增量全量标识}]。\n命名说明：\n统计时间周期范围在默认情况下，离线计算应该包括最近一天（1d）、最近N天（nd）和历史截至当天（td）三个表。如果nd表的字段过多，需要拆分时，只允许以一个统计周期单元作为原子拆分，即一个统计周期拆分一个表。例如，最近7天（1w）拆分一个表，不允许拆分出来的一个表存储多个统计周期。\n对于{刷新周期标识}和{单分区增量全量标识}在汇总层不做强制要求。\n刷新周期标识：mi表示分钟，h表示小时，d表示天，w表示周，m表示月，y表示年\n对于小时表不管是按天刷新还是按小时刷新，都用_h来表示。\n对于分钟表不管是按天刷新还是按小时刷新，都用_m来表示。\n单分区增量全量标识：i表示增量，f表示全量。\n7.3 数据存储及生命周期管理规范 # CDM汇总层的表的类型为事实表或维度宽表，存储方式为按天分区\n事务型事实表一般会永久保存。周期快照型事实表根据业务需求设置生命周期管理。可依据3个月内的最大需要访问的跨度设置保留策略，具体计算方式如下：\n当3个月内的最大访问跨度小于或等于4天时，建议将保留天数设为7天。\n当3个月内的最大访问跨度小于或等于12天时，建议将保留天数设为15天。\n当3个月内的最大访问跨度小于或等于30天时，建议将保留天数设为33天。\n当3个月内的最大访问跨度小于或等于90天时，建议将保留天数设为93天。\n当3个月内的最大访问跨度小于或等于180天时，建议将保留天数设为183天。\n当3个月内的最大访问跨度小于或等于365天时，建议将保留天数设为368天。\n8 ADS应用数据层设计规范 # 应用数据层将不同数据域的汇总数据预关联在一个物理表，开放给应用使用，以减少应用层多次重复JOIN的成本开销\n8.1 命名规范 # 命名规则：{project_name/database}.ads_{业务缩写/pub}_{数据域/hbd}_{数据粒度缩写}[_{自定义表命名标签缩写}][_{统计时间周期范围缩写}]。\n统计时间周期范围和数据域说明如下：\n统计时间周期范围缩写，离线计算包括最近一天（1d）、 最近N天（nd）和历史截至当天（td）。 说明 如果出现nd 的表字段过多，需要拆分时，只允许以一个统计周期单元作为原子拆分，即一个统计周期拆分一个表，例如最近7天（1week）拆分一个表，不允许拆分出一个表存储多个统计周期。\n如果一个汇总表出现混合多个数据域时，表名称中需要使用hbd（hybird 缩写）进行标识。 9. 其他命名规范 # 9.1 视图命名规范 # 视图命名规范如下：\nODS层直接以视图形式开放到CDM层：{project_name/database}.dwd_{ODS 表名}_view。\n中间层视图命名规范：遵循中间层命名规范，且加上后缀{project_name/database}.{dws/dwd}_{中间层表命名规范要求}_view。\n","date":"2023.04.04","externalUrl":null,"permalink":"/docs/datawarehouse-standard/","section":"博客文章","summary":"阿里云数据仓库开发手册","title":"数仓搭建开发规范-阿里云","type":"docs"},{"content":"","date":"12 April 2023","externalUrl":null,"permalink":"/en/series/blog/","section":"Series","summary":"","title":"Blog","type":"series"},{"content":"","date":"12 April 2023","externalUrl":"https://moretothat.com/money/","permalink":"/en/docs/%E9%92%B1%E6%98%AF%E8%BA%AB%E4%BB%BD%E7%9A%84%E4%BC%A0%E5%A3%B0%E7%AD%92/","section":"Posts","summary":"","title":"Money Is the Megaphone of Identity","type":"docs"},{"content":"","date":"12 April 2023","externalUrl":null,"permalink":"/en/tags/pkm/","section":"Tags","summary":"","title":"PKM","type":"tags"},{"content":"","date":"2022.12.12","externalUrl":null,"permalink":"/tags/think/","section":"Tags","summary":"","title":"Think","type":"tags"},{"content":" 对时间认知 # 时间量化 # 《超体》中对时间的解读 # 时间衡量存在的唯一尺度\n过去、现在、未来，时间一直都是一个永恒的存在。生命从无到有，无一不是置身于时间的流逝之中，作为地球上已知最富智慧的物种，到目前人类似乎也无法对时间进行改变。而海德格尔却以一种多维度的视角，将自然科学中的时间和历史学中的时间作出区分，指出自然科学中的时间是一种客观的、可供量化、\u0026ldquo;无人\u0026quot;的时间，也就是人们通常以为的时间概念。\n在电影《超体》中，大脑得到前所未有开发的露西认为人类将自己存在的理论建立在自身的独特性之上，通过制定各种测量单位和准则形成在人类社会范围内可供理解的规范，这实际上是将人类生命存在简化的结果。如果人类不是衡量标准，而世界也不是依靠数学法则，那么应该如何证明生命的存在？电影给出了答案：时间，只有时间才能证明物质的存在，没有时间，生命也就不再存在。而对人类来说，时间的全部意义就在于存在的意义，人有时间性并不是因为他处于时间之流中，而是因为时间性构成他最内在的本质核心，时间才是衡量人类生命存在的唯一尺度。1\nPhoto from DouBan 《超体 Lucy》 对时间管理做的事情 # 设定明确的目标 # 只有明确的目标才能帮助你确定优先级。长期、中期和短期目标都需要清晰，以便规划行动\n优先级管理（重要-紧急矩阵） # 区分任务的优先级，按照重要性和紧急性划分任务。优先处理那些既重要又紧急的任务，减少低价值任务的时间投入 番茄工作法 任务分解 利用好碎片时间 GTD（Getting Things Done） # 收集箱（Inbox） 执行清单（@Context task） 等待清单（\u0026ldquo;Waiting for\u0026rdquo; task） 项目清单（\u0026ldquo;Plan project\u0026rdquo; plan） 可能清单（Someday/maybe） 参考资料（Reference） 回收箱（Trash） SMART 原则 # 80/20 法则（帕累托法则） # 时间块管理法（Time Blocking） # 时间管理四象限（（艾森豪威尔矩阵） # 提升时间管理的习惯 # 每天计划：每天花几分钟列出一天的待办事项，确保你知道每天的任务目标。 回顾总结：每周或每月进行总结，反思哪些任务是有效的，哪些时间管理策略可以改进。 建立例行流程：通过建立固定的工作和生活流程，减少决策时间，例如每天固定时间处理邮件，固定时间锻炼等。 保持健康：健康的身体和精神状态能够帮助提升效率，保持足够的睡眠和休息。 时间的价值 # 村上春树24小时作息时间表 # 村上春树自言，写小说时早上五点起床，写作工作到早上十点半（中间插入早餐时间），然后游泳或跑步。吃完午餐，下午则是从事写作以外工作，像是翻译或写杂志随笔，处理日常杂务。晚上看看录影带或听音乐、看书，除非特殊情由，否则日落后便不工作。晚上九点十点就睡觉了\n与时间做朋友 # 时间管理工具 # 任务管理工具： Todoist：帮助组织待办事项，设定优先级。 Microsoft To Do：微软推出的任务管理工具，支持跨平台同步。 Trello：基于看板的任务管理工具，适合团队协作。 日程安排工具： Google Calendar：在线日历工具，支持创建和共享日程。 Outlook Calendar：微软的日程安排工具，支持和电子邮件集成。 Apple Calendar：苹果生态的日历工具，适合苹果设备用户。 时间跟踪工具： RescueTime：帮助你了解每天的时间花在哪些活动上，提供详细的时间使用报告。 Toggl：简单的时间跟踪工具，帮助记录每个任务的时间花费。 番茄钟工具： Pomodone：基于番茄工作法的时间管理工具，可以和任务管理应用集成。 Focus Booster：帮助进行番茄工作法的时间管理工具。 Rob Pike1\n时间、自由与责任：电影《超体》的存在主义解读 By wangxiaoran, November 14, 2019.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022.12.12","externalUrl":null,"permalink":"/docs/005-time-mange/","section":"博客文章","summary":"时间管理是一种通过计划和组织来提高效率、优先处理任务的方法，帮助我们在有限的时间内更好地达成目标。有效的时间管理不仅可以提高工作效率，还能减少压力，改善生活质量.","title":"时间管理","type":"docs"},{"content":"","date":"2022.07.07","externalUrl":null,"permalink":"/tags/model/","section":"Tags","summary":"","title":"Model","type":"tags"},{"content":"","date":"2022.07.07","externalUrl":null,"permalink":"/tags/reship/","section":"Tags","summary":"","title":"Reship","type":"tags"},{"content":"“你生命中最大的挑战是什么？”\n在某论坛上，埃隆·马斯克面对这个问题，足足想了30秒，给出了一个非常精彩的回答：\n确保你有一个可纠错的反馈闭环。\n可纠错的反馈闭环，几乎是“创业、投资、成长”等问题的核心答案.然而，如果不能将其与贝叶斯公式的计算结合起来，这个提法就和所有解释性\n概念一样，只能作为一篇营销文或图书的标题而已。反之亦然。贝叶斯公式伴随着AI的再次火热，又频繁出现在人们面前。\n本文将从“可纠错的反馈闭环”和“贝叶斯公式”两头出发，给出一个不确定年代，尤显重要的思考和行动框架：\n1、接受不确定性，用概率思维来预测和决策； 2、快速行动和迭代，打造“知行一体”的反馈飞轮； 3、用贝叶斯公式实现“有系统”的复利效应； 4、重视基础概率，基于整体资产滚雪球； 5、对新信息保持“敏感”，又有独立判断的“钝感”； 6、别太完美，降低自己被证伪的概率； 7、成为学习机器，在适应中快速进化； 8、探索未知 \u0026amp; 利用已知，在攻和守之间进行权衡； 9、理解贝叶斯的局限，小心应对黑天鹅事件 基于以上9个要点，我们就能更完整地理解“可纠错的反馈闭环”。‍‍‍‍‍这是贝叶斯主义的现实模型，也是“真正的高手”的秘密！\n贝叶斯主义是一种关于概率和统计的哲学观点，它强调信念的主观性和更新。在该观点中，贝叶斯公式是一个核心的工具，用于处理不确定性，更新信念，并指导决策。\n总的来说，贝叶斯公式与很多关于知识、学习、不确定性和决策的哲学思想有关。它提供了一种极为强大的框架，用于理解和处理这些复杂的问题。\n接受不确定性，用概率思维来预测和决策\n大约是在三年前，一位年轻的老师有很好的内容，想在抖音和视频号上做自己的IP，但是她又担心：万一自己辛苦一番，抖音和视频号又不火了呢？\n“确保成功”，似乎是很多人做决定的前提。但这个世界上并没有什么事情是确定的。\n残酷的一面是，越是追求”确保成功“的人，反而越脆弱，越容易掉入决策的陷阱。例如，市面上的种种骗术都是以”确保成功“为吸引点的。\n不光骗子如此，流行文化，甚至主流文化也因为实用主义的偏好，而形成了“要么成功要么失败”的黑白分明价值观。\n一个朋友对我说，短视频的流行密码，就是两个：\n1、承诺只要做以下三点，你就可以实现某某目标 2、只要实现第一点，你就能发财 于是，面对不确定性，黑白分明的世界观容易产生两种极端的行为\nA、要么“不见兔子不撒鹰”，追求不存在的“确保成功” B、要么“人生就是赌一把”，见一个热点就“All in”一个 对于贝叶斯主义者，世界是灰度的。原因如下：\n没有人能给这个复杂的世界算命。随着时间的变化，一切都在变化，即使存在如上不确定性，世界也很难精确预测，但我们仍然可以用概率来描述世界\n从世俗成败的角度看，赢家只需要在局部获得相对优势，就能够领先于对手。所以，很多赢家只要获胜的概率比赢家多几个百分点，就能够成功\n从概率的认知和判断，是一个不断逼近、不断进化的过程\n对不确定性的接受和理解，是贝叶斯思维的核心。我们需要接受事物的不确定性，并利用概率来描述和理解它 面对不确定性，贝叶斯思想鼓励我们不怕犯错误，尝试新的事物，从失败中学习，调整策略，这与实现个人成长的过程非常匹配。概率不仅用于量化现实世界的不确定性，也用于评估我们自己的决策质量 在面临选择时，贝叶斯思维鼓励我们基于概率来做决策，而非绝对肯定或否定。这能够帮助年轻人更好地处理复杂的决策问题。桥水基金使用了一种称为\u0026quot;贝叶斯加权\u0026quot;的决策过程，这个过程明确地将贝叶斯推理纳入了决策过程中，该公司使用算法来分配决策权重，这是一种基于贝叶斯推理的决策过程，对于每一个决策，该公司都会将决策者的可靠性、专业知识等因素考虑进来，然后根据这些因素分配权重，最终做出决策。对比起频率派，贝叶斯主义者对概率的理解有所不同\n【转】原文作者：孤独大脑\n","date":"2022.07.07","externalUrl":null,"permalink":"/docs/bei-ye-si/","section":"博客文章","summary":"贝叶斯主义是一种关于概率和统计的哲学观点，它强调信念的主观性和更新。在该观点中，贝叶斯公式是一个核心的工具，用于处理不确定性，更新信念，并指导决策。“可纠错的反馈闭环”结合“贝叶斯公式”辅助你形成自己的行动思考框架","title":"贝叶斯主义者如何思考","type":"docs"},{"content":"","date":"2022.05.05","externalUrl":"https://timconnors.co/posts/ai-scraper","permalink":"/docs/spider/","section":"博客文章","summary":"HTML + Text Search + Text Model","title":"Building a Universal AI Scraper","type":"docs"},{"content":"","date":"2022.05.05","externalUrl":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"MySQL","type":"tags"},{"content":" Background # 在数据迁移和转换过程中，将 MySQL 表结构转换为 ODPS 表结构是一项常见需求。由于 MySQL 和 ODPS 的数据类型和语法存在差异，手动转换可能耗时且易出错。通过 PyODPS，可以高效地实现 MySQL DDL 到 ODPS DDL 的批量转换\n环境配置 # Warning! 数据库信息：确保您拥有 MySQL 数据库的访问权限，并拥有 information_schema 的访问权限 操作系统：Windows 或 Linux 依赖库：MySQLdb 安装方式：pip install mysqlclient Coding # #!/usr/bin/python # -*- coding: UTF-8 -*- # author: xuf import MySQLdb # MySQL数据库配置 DB_CONFIG = { \u0026#39;host\u0026#39;: \u0026#39;数据库地址\u0026#39;, \u0026#39;user\u0026#39;: \u0026#39;用户\u0026#39;, \u0026#39;passwd\u0026#39;: \u0026#39;密码\u0026#39;, \u0026#39;db\u0026#39;: \u0026#39;mysql\u0026#39;, \u0026#39;charset\u0026#39;: \u0026#39;utf8\u0026#39; } # 目标配置 TARGET_SCHEMA = \u0026#39;odps_project\u0026#39; # ODPS 对应项目名称 SYS_ID = \u0026#39;ods\u0026#39; # 表名前缀，用于规范命名 # 数据类型映射 TYPE_MAPPING = { \u0026#39;varchar\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;char\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;longtext\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;float\u0026#39;: \u0026#39;double\u0026#39;, \u0026#39;tinyint\u0026#39;: \u0026#39;int\u0026#39;, \u0026#39;timestamp\u0026#39;: \u0026#39;datetime\u0026#39;, \u0026#39;date\u0026#39;: \u0026#39;string\u0026#39; } def connect_to_db(): \u0026#34;\u0026#34;\u0026#34;创建并返回数据库连接对象\u0026#34;\u0026#34;\u0026#34; return MySQLdb.connect(**DB_CONFIG) def exec_sql(conn, sql, params=None): \u0026#34;\u0026#34;\u0026#34;执行 SQL 并返回结果\u0026#34;\u0026#34;\u0026#34; cursor = conn.cursor() cursor.execute(sql, params or ()) rows = cursor.fetchall() cursor.close() return rows def map_data_type(mysql_type): \u0026#34;\u0026#34;\u0026#34;将 MySQL 数据类型映射为 ODPS 数据类型\u0026#34;\u0026#34;\u0026#34; return TYPE_MAPPING.get(mysql_type, mysql_type) def clean_comment(comment): \u0026#34;\u0026#34;\u0026#34;清理注释字段，移除特殊字符\u0026#34;\u0026#34;\u0026#34; if comment: return comment.replace(\u0026#39;\\r\\n\u0026#39;, \u0026#39;\\\\r\\\\n\u0026#39;).replace(\u0026#39;\\n\u0026#39;, \u0026#39;\\\\n\u0026#39;) return \u0026#34;\u0026#34; def get_table_names(conn): \u0026#34;\u0026#34;\u0026#34;获取数据库中所有表名\u0026#34;\u0026#34;\u0026#34; sql = \u0026#34;\u0026#34;\u0026#34; SELECT table_name FROM information_schema.TABLES WHERE TABLE_SCHEMA=%s AND table_type=\u0026#39;BASE TABLE\u0026#39; \u0026#34;\u0026#34;\u0026#34; return exec_sql(conn, sql, (DB_CONFIG[\u0026#39;db\u0026#39;],)) def get_table_columns(conn, table_name): \u0026#34;\u0026#34;\u0026#34;获取指定表的列信息\u0026#34;\u0026#34;\u0026#34; sql = \u0026#34;\u0026#34;\u0026#34; SELECT TABLE_NAME, COLUMN_NAME, CASE WHEN DATA_TYPE IN (\u0026#39;varchar\u0026#39;, \u0026#39;char\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;longtext\u0026#39;, \u0026#39;text\u0026#39;) THEN \u0026#39;string\u0026#39; WHEN DATA_TYPE = \u0026#39;float\u0026#39; THEN \u0026#39;double\u0026#39; WHEN DATA_TYPE = \u0026#39;tinyint\u0026#39; THEN \u0026#39;int\u0026#39; WHEN DATA_TYPE = \u0026#39;timestamp\u0026#39; THEN \u0026#39;datetime\u0026#39; ELSE DATA_TYPE END AS DATA_TYPE, COLUMN_COMMENT FROM information_schema.COLUMNS WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s ORDER BY ORDINAL_POSITION \u0026#34;\u0026#34;\u0026#34; return exec_sql(conn, sql, (DB_CONFIG[\u0026#39;db\u0026#39;], table_name)) def get_table_comment(conn, table_name): \u0026#34;\u0026#34;\u0026#34;获取表的注释信息\u0026#34;\u0026#34;\u0026#34; sql = f\u0026#34;SHOW CREATE TABLE {DB_CONFIG[\u0026#39;db\u0026#39;]}.{table_name}\u0026#34; result = exec_sql(conn, sql) ddl_info = result[0][1] if \u0026#39;COMMENT=\u0026#39; in ddl_info: comment_start = ddl_info.index(\u0026#39;COMMENT=\u0026#39;) + len(\u0026#39;COMMENT=\u0026#39;) return ddl_info[comment_start:].replace(\u0026#39;=\u0026#39;, \u0026#39; \u0026#39;) return \u0026#34;COMMENT \u0026#39;\u0026#39;\u0026#34; def generate_ddl(conn): \u0026#34;\u0026#34;\u0026#34;生成所有表的 ODPS DDL 语句\u0026#34;\u0026#34;\u0026#34; out_comment = [] table_names = get_table_names(conn) for (table_name,) in table_names: columns = get_table_columns(conn, table_name) table_comment = get_table_comment(conn, table_name) ddl_info = [f\u0026#34;CREATE TABLE IF NOT EXISTS {TARGET_SCHEMA}.{SYS_ID}_{table_name} (\u0026#34;] for col in columns: col_name = col[1].upper() col_type = map_data_type(col[2]).upper() col_comment = clean_comment(col[3]) ddl_info.append(f\u0026#34; {col_name} {col_type} COMMENT \u0026#39;{col_comment}\u0026#39;,\u0026#34;) ddl_info[-1] = ddl_info[-1][:-1] # 去掉最后一个逗号 ddl_info.append(\u0026#34;)\u0026#34;) ddl_info.append(f\u0026#34;{table_comment} PARTITIONED BY (PT STRING COMMENT \u0026#39;数据日期\u0026#39;)\u0026#34;) out_comment.append(f\u0026#34;-- {table_name}\\n\u0026#34; + \u0026#34;\\n\u0026#34;.join(ddl_info) + \u0026#34;;\\n\u0026#34;) return \u0026#34;\\n\u0026#34;.join(out_comment) def write_to_file(content, file_path): \u0026#34;\u0026#34;\u0026#34;将内容写入文件\u0026#34;\u0026#34;\u0026#34; with open(file_path, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as file: file.write(content) if __name__ == \u0026#34;__main__\u0026#34;: conn = connect_to_db() try: ddl_content = generate_ddl(conn) output_file = f\u0026#34;D:\\\\data\\\\output\\\\{SYS_ID}_{DB_CONFIG[\u0026#39;db\u0026#39;]}.sql\u0026#34; write_to_file(ddl_content, output_file) print(f\u0026#34;DDL 文件已生成：{output_file}\u0026#34;) finally: conn.close() ","date":"2022.05.05","externalUrl":null,"permalink":"/docs/mysql-ddl-mapping-odps-ddl/","section":"博客文章","summary":"","title":"MySQL DDL 批量映射 ODPS DDL 脚本","type":"docs"},{"content":"","date":"2022.05.05","externalUrl":null,"permalink":"/tags/script/","section":"Tags","summary":"","title":"Script","type":"tags"},{"content":"","date":"12 April 2021","externalUrl":null,"permalink":"/en/tags/blog/","section":"Tags","summary":"","title":"Blog","type":"tags"},{"content":"","date":"12 April 2021","externalUrl":"http://m.signalvnoise.com/ive-never-had-a-goal/","permalink":"/en/docs/%E6%88%91%E4%BB%8E%E6%9D%A5%E6%B2%A1%E6%9C%89%E7%9B%AE%E6%A0%87/","section":"Posts","summary":"","title":"I’ve never had a goal","type":"docs"},{"content":"","date":"2021.04.04","externalUrl":null,"permalink":"/tags/wiki/","section":"Tags","summary":"","title":"Wiki","type":"tags"},{"content":" 什么是数据花园？ # 数据花园（Digital Garden）是一个类比的概念，借用了园艺中“种植与培育”的比喻。正如在一个真实的花园里，我们播种、浇水、修剪，以确保植物健康成长；在数据花园中，我们对信息和知识进行有机地管理和优化，推动知识的进化和提升。其特点是非线性的，动态的知识组织结构，允许知识随着时间的推移不断生长和变化。\n与传统的笔记或博客不同，数据花园不是一次性发布内容的集散地，而是一个持续演变的知识体系。你可以将它理解为个人的知识库（Personal Knowledge Base, PKB），但它更注重知识的连贯性和可持续性。\nRoam research\n为什么要构建数据花园？ # 知识管理的核心在于让信息“有用”。在当今的工作和学习环境中，我们每天接触大量信息，但不加筛选或分类的知识就像荒草丛生的花园，不仅难以维护，还阻碍了个人成长的空间。构建数据花园的优势在于：\n1.\t促进深度思考与联系：数据花园鼓励通过内部链接或交叉引用将知识串联起来，从而建立不同概念之间的联系，推动深度理解。 2.\t动态更新与迭代：知识是动态的，数据花园允许我们对已有的知识进行持续更新和优化，而不是写下一个结论后就一劳永逸。 3.\t个性化知识体系：你可以按照自己的需求和理解来组织知识，这种个性化的结构更有利于知识的内化与记忆。 4.\t长期知识保值：通过有意识地构建与管理知识，你可以打造一个长期可用的知识库，帮助你在学习、工作中做出更明智的决策。 如何构建你的数据花园？ # 知识捕捉：信息收集与筛选 # 知识管理的第一步是捕捉信息。这一步看似简单，但需要我们具备良好的信息筛选能力。在信息泛滥的当下，能够从大量的信息中迅速抓住重点，并将其转化为可操作的知识，显得尤为重要。\n•\t使用 RSS 聚合器或书签工具定期收集有价值的内容。 •\t运用标签分类法，帮助你快速归类信息。 知识整理：搭建结构化体系 # 收集的信息如果没有经过整理，只能算是无序的“数据堆积”。构建数据花园的关键在于搭建清晰的结构化体系：\n•\t层次化结构：根据主题或领域将知识分层归类，形成从宏观到微观的知识网络。 •\t链接与引用：将相关的知识点通过链接方式串联起来，形成一个有机的知识体系，类似于网络中节点的连接方式。 知识沉淀：持续迭代与优化 # 知识管理是一个持续迭代的过程，数据花园的关键特性在于它的动态性。我们需要定期回顾已有的知识，进行优化和更新：\n•\t定期复盘：对已有的知识进行定期复盘，加入新的见解或修正过时的观点。 •\t知识输出：通过博客、讨论等方式将知识输出，验证你的理解和认知，同时也可以通过互动获取新的信息反馈。 工具选择：构建数据花园的数字工具 # 构建数据花园并不意味着你需要高深的技术背景，事实上，许多工具可以帮助你轻松开始：\n•\tObsidian：一款流行的知识管理工具，支持Markdown，允许你通过双向链接快速建立知识网络，非常适合数据花园的构建。 •\tNotion：支持灵活的页面创建和知识管理，用户可以通过其强大的数据库功能实现知识的系统化管理。 •\tRoam Research：以双向链接和块级引用为核心，支持非线性笔记，非常适合构建动态的知识体系。 •\tHugo + Git：对于希望将知识花园公开发布的人，静态网站生成器如 Hugo 可以帮助你构建高效的知识展示平台。 一些优秀的花园推荐 # Hypertext Gardens published in 1998 by Eastgate Systems, Inc. All Rights Reserved. 小冯的数字花园 Reference # 封面图片来自于 https://www.eastgate.com/garden/Enter.html ","date":"2021.04.04","externalUrl":null,"permalink":"/docs/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E8%8A%B1%E5%9B%AD/","section":"博客文章","summary":"构建一个数据花园不仅是提升个人或企业知识管理能力的有力工具，也是一种提升认知水平、增强决策能力的方式。通过持续捕捉、整理和优化知识，我们能够在信息的海洋中收获真正有价值的洞见，推动自身和组织的持续成长。","title":"知识管理体系：构建你的数据花园","type":"docs"},{"content":" Collection Web Informaion # graph LR; A[Website]-- SaveToNotion ---\u003eB[Notion]; B--\u003eC[Summary] C--\u003eD[Share] Template # pathpapages: Get Organized \u0026amp; Productive With Notion Templates 7 templates to automate your work with Buttons Behance: Desgin Notion Red’s Notion Templates My Eisenhower Matrix In Notion (Free Template) 阿汪同学的小世界 · 模版资源 Awesome Knowledge # bojne: Working on product \u0026amp; engineering problems at Meta #bloger pmthinking:Product thinking \u0026amp; 产品沉思录™ By ShaoNan #bloger 春殿的手账本: 无穷的远方，无数的人们，都与我无关 #bloger Travis Fischer: notion → next.js → website blog #tutorial #bloger all things \u0026amp; tools of topbook here: by topbook Notion Tools: 第三方的工具、资源集合导航网站 illustrations \u0026amp; Icon \u0026amp; photoa # illustrations: illustrations by super.so tutorial # Notion Fundamentals How to Build a Content Management System Using the Notion API 用 GitHub Actions 给 notion 做自动备份 Build Notion Blog Website 结合Notion API创建个人网站 Notion Community # NotionChina: Notion中文用户指南，这里有免费的中文用户指南、工具、资源、模版供你学习和使用 ","date":"2015.03.03","externalUrl":null,"permalink":"/docs/how-to-use-notion/","section":"博客文章","summary":"About my use of notion to build my personal knowledge system. Includes notion database, table, function, extension, template.","title":"How to use Notion","type":"docs"},{"content":"","date":"2015.03.03","externalUrl":null,"permalink":"/tags/knowledge/","section":"Tags","summary":"","title":"Knowledge","type":"tags"},{"content":"","date":"2015.03.03","externalUrl":null,"permalink":"/tags/notion/","section":"Tags","summary":"","title":"Notion","type":"tags"},{"content":" 云南 Coffee 庄园 # 威尔士公里 # 跟随者汽车导航，穿越山间村庄，来到了公路的尽头，这条公路被命名为“威尔士公里 \u0026amp; Weier roadway” ，在博物馆中你可以详细的了解到整个公里的建造历史。\nxx咖啡庄园 # 小粒咖啡 # 挂耳咖啡 # 拼配豆 # 大理咖啡 # 古城-孟旺咖啡 # 古城-如是咖啡 # 古城-唐咖 # 古城-愚咖啡 # 银桥-锡安咖啡 # 银桥-罐子咖啡 # # 沙溪- # ","date":"2015.03.03","externalUrl":null,"permalink":"/travel/yunnan-coffee/","section":" Experience","summary":"","title":"大理 Coffee","type":"travel"},{"content":" DQL \u0026amp; AI # 在数据驱动的现代业务环境中，AI和SQL工具的结合为数据分析和决策提供了强大支持。通过AI的自动化分析和预测功能，以及SQL的强大数据查询和处理能力，企业能够更高效地处理大量复杂数据，实现数据的快速查询、清洗和优化。AI技术可以帮助识别模式、自动生成SQL查询、优化查询速度，甚至自动分析数据集，生成可操作的业务洞见。这种结合不仅提升了数据分析的效率，还降低了数据操作的门槛，使非技术人员也能够轻松获得数据洞察，从而帮助企业在市场竞争中获得优势\nAI \u0026amp; DQL # 1. postgres.build # supabase-community/postgres-new In-browser Postgres sandbox with AI assistance TypeScript 2425 189 通过AI对话框自动创建表结构，并生成对应的逻辑图\n2. Chat2DB # CodePhiliaX/Chat2DB 🔥🔥🔥AI-driven database tool and SQL client, The hottest GUI client, supporting MySQL, Oracle, PostgreSQL, DB2, SQL Server, DB2, SQLite, H2, ClickHouse, and more. Java 16362 1842 3. DB-GPT-Hu # eosphoros-ai/DB-GPT-Hub A repository that contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance in Text-to-SQL Python 1432 185 ","date":"2014.03.03","externalUrl":null,"permalink":"/docs/database-ai/","section":"博客文章","summary":"AI赋能数据工程正在彻底改变数据处理和分析的方式。通过自动化数据清洗、数据集成、数据治理等关键流程。AI算法能够自动识别数据模式、修复异常值、补全缺失数据，从而减少人工干预。在大模型能力不断增强的情况下，大数据生态中的产品也会AI进行优化重构。","title":"Big Data With AI","type":"docs"},{"content":"Big Data Blog \u0026amp; Digital Garden.\n","externalUrl":null,"permalink":"/en/todo/","section":" 博客","summary":"","title":" 博客","type":"todo"},{"content":" ","externalUrl":null,"permalink":"/travel/bike/","section":" Experience","summary":"","title":"【骑行】2023 ","type":"travel"},{"content":"","externalUrl":null,"permalink":"/tags/bike/","section":"Tags","summary":"","title":"Bike","type":"tags"},{"content":"","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/tags/play/","section":"Tags","summary":"","title":"Play","type":"tags"},{"content":"","externalUrl":null,"permalink":"/en/topics/","section":"Topics","summary":"","title":"Topics","type":"topics"},{"content":"","externalUrl":null,"permalink":"/en/xufei/","section":"Xufei","summary":"","title":"Xufei","type":"xufei"},{"content":" 蒙餐 AWESOME 云雀面包 🥖 🌭 🍞 🥯 🥨 🧀 🥞 🥪 🧁 🍰 🍩 🎂 火锅 AWESOME 轻食 AWESOME 减脂餐 朋友聚餐 AWESOME 其他小吃 AWESOME ","externalUrl":null,"permalink":"/travel/midnight-restaurant/","section":" Experience","summary":"每个人都有的深夜食堂","title":"深夜食堂 - 未完...","type":"travel"}]